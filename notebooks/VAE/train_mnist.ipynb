{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62e00a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import random, vmap, pmap, local_devices, local_device_count\n",
    "\n",
    "from models import VariationalAutoencoder\n",
    "from input_pipeline import MNISTVAEDataLoader\n",
    "\n",
    "import wandb\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from configs.default import get_config\n",
    "\n",
    "print(local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2846079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                  VAE Summary                                   \u001b[0m\n",
      "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams        \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
      "│               │ VAE         │ -             │ \u001b[2mfloat32\u001b[0m[1,78… │                │\n",
      "│               │             │ \u001b[2mfloat32\u001b[0m[1,78… │               │                │\n",
      "│               │             │ - \u001b[2mfloat32\u001b[0m[16] │               │                │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ encoder       │ MlpEncoder  │ -             │ -             │                │\n",
      "│               │             │ \u001b[2mfloat32\u001b[0m[1,78… │ \u001b[2mfloat32\u001b[0m[1,16] │                │\n",
      "│               │             │ - \u001b[2mfloat32\u001b[0m[16] │ - \u001b[2mfloat32\u001b[0m[1]  │                │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ encoder/Gaus… │ GaussianMlp │ \u001b[2mfloat32\u001b[0m[1,78… │ -             │                │\n",
      "│               │             │               │ \u001b[2mfloat32\u001b[0m[1,16] │                │\n",
      "│               │             │               │ -             │                │\n",
      "│               │             │               │ \u001b[2mfloat32\u001b[0m[1,16] │                │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ encoder/Gaus… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,78… │ \u001b[2mfloat32\u001b[0m[1,64] │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[64]    │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[784,6… │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m50,240 \u001b[0m\u001b[1;2m(201.0 \u001b[0m │\n",
      "│               │             │               │               │ \u001b[1;2mKB)\u001b[0m            │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ encoder/Gaus… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,64] │ \u001b[2mfloat32\u001b[0m[1,64] │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[64]    │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[64,64] │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m4,160 \u001b[0m\u001b[1;2m(16.6 \u001b[0m   │\n",
      "│               │             │               │               │ \u001b[1;2mKB)\u001b[0m            │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ encoder/Gaus… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,64] │ \u001b[2mfloat32\u001b[0m[1,64] │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[64]    │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[64,64] │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m4,160 \u001b[0m\u001b[1;2m(16.6 \u001b[0m   │\n",
      "│               │             │               │               │ \u001b[1;2mKB)\u001b[0m            │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ encoder/Gaus… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,64] │ \u001b[2mfloat32\u001b[0m[1,16] │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[16]    │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[64,16] │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m1,040 \u001b[0m\u001b[1;2m(4.2 KB)\u001b[0m │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ encoder/Gaus… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,64] │ \u001b[2mfloat32\u001b[0m[1,16] │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[16]    │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[64,16] │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m1,040 \u001b[0m\u001b[1;2m(4.2 KB)\u001b[0m │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ decoder       │ Mlp         │ \u001b[2mfloat32\u001b[0m[1,16] │ \u001b[2mfloat32\u001b[0m[1,78… │                │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ decoder/Dens… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,16] │ \u001b[2mfloat32\u001b[0m[1,12… │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[128]   │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[16,12… │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m2,176 \u001b[0m\u001b[1;2m(8.7 KB)\u001b[0m │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ decoder/Dens… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,12… │ \u001b[2mfloat32\u001b[0m[1,12… │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[128]   │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[128,1… │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 \u001b[0m  │\n",
      "│               │             │               │               │ \u001b[1;2mKB)\u001b[0m            │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ decoder/Dens… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,12… │ \u001b[2mfloat32\u001b[0m[1,12… │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[128]   │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[128,1… │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m16,512 \u001b[0m\u001b[1;2m(66.0 \u001b[0m  │\n",
      "│               │             │               │               │ \u001b[1;2mKB)\u001b[0m            │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│ decoder/Dens… │ Dense       │ \u001b[2mfloat32\u001b[0m[1,12… │ \u001b[2mfloat32\u001b[0m[1,78… │ bias:          │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[784]   │\n",
      "│               │             │               │               │ kernel:        │\n",
      "│               │             │               │               │ \u001b[2mfloat32\u001b[0m[128,7… │\n",
      "│               │             │               │               │                │\n",
      "│               │             │               │               │ \u001b[1m101,136 \u001b[0m\u001b[1;2m(404.5\u001b[0m │\n",
      "│               │             │               │               │ \u001b[1;2mKB)\u001b[0m            │\n",
      "├───────────────┼─────────────┼───────────────┼───────────────┼────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m196,976 \u001b[0m\u001b[1;2m(787.9\u001b[0m\u001b[1m \u001b[0m│\n",
      "│\u001b[1m               \u001b[0m│\u001b[1m             \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m               \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\n",
      "└───────────────┴─────────────┴───────────────┴───────────────┴────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                      Total Parameters: 196,976 \u001b[0m\u001b[1;2m(787.9 KB)\u001b[0m\u001b[1m                      \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create model from config\n",
    "config = get_config()\n",
    "model = VariationalAutoencoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd3854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpgp\u001b[0m (\u001b[33mjaxpi\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/paris/Downloads/VAE/wandb/run-20250429_132729-amwl5o90</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jaxpi/MNIST/runs/amwl5o90' target=\"_blank\">clean-surf-8</a></strong> to <a href='https://wandb.ai/jaxpi/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jaxpi/MNIST' target=\"_blank\">https://wandb.ai/jaxpi/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jaxpi/MNIST/runs/amwl5o90' target=\"_blank\">https://wandb.ai/jaxpi/MNIST/runs/amwl5o90</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jaxpi/MNIST/runs/amwl5o90?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ac9e4c50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create wandb instance\n",
    "wandb_config = config.wandb\n",
    "wandb.init(project=wandb_config.project,\n",
    "            name=wandb_config.name,\n",
    "            config=dict(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b784a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation step\n",
    "def eval_step(config, model, batch):\n",
    "\n",
    "    params = model.state.params\n",
    "    log_dict = {}\n",
    "\n",
    "    if config.logging.log_losses:\n",
    "        kl_loss, recon_loss = model.eval_losses(params, batch)\n",
    "        kl_loss = kl_loss.mean()\n",
    "        recon_loss = recon_loss.mean()\n",
    "        log_dict['kl_loss'] = kl_loss\n",
    "        log_dict['recon_loss'] = recon_loss\n",
    "\n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2374b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX running on 1 devices\n",
      "Global batch size: 32\n",
      "Per-device batch size: 32\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcfaf19224044d9a4fd61120846f148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/37500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 0 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 700 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 900 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1700 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 0 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 700 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 900 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1700 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 0 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 700 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 900 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1700 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 0 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 700 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 900 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1000 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1100 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1200 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1300 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1400 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1500 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1600 that is less than the current step 1800. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m images, labels, eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_ds)\n\u001b[1;32m     24\u001b[0m batch \u001b[38;5;241m=\u001b[39m (images, eps)\n\u001b[0;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstep(model\u001b[38;5;241m.\u001b[39mstate, batch)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mlog_every_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m     log_dict \u001b[38;5;241m=\u001b[39m eval_step(config, model, batch)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/jax/_src/api.py:1602\u001b[0m, in \u001b[0;36m_cpp_pmap.<locals>.<lambda>\u001b[0;34m(x, s)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     fastpath_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out, fastpath_data\n\u001b[1;32m   1600\u001b[0m cpp_mapped_f \u001b[38;5;241m=\u001b[39m pmap_lib\u001b[38;5;241m.\u001b[39mpmap(\n\u001b[1;32m   1601\u001b[0m     fun, cache_miss, static_broadcasted_tuple,\n\u001b[0;32m-> 1602\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x, s: pxla\u001b[38;5;241m.\u001b[39mshard_args([s], [\u001b[38;5;28;01mNone\u001b[39;00m], [\u001b[38;5;28;01mNone\u001b[39;00m], [x])[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1603\u001b[0m     pytree_registry\u001b[38;5;241m=\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mdefault_registry)\n\u001b[1;32m   1604\u001b[0m _pmap_cache_clears\u001b[38;5;241m.\u001b[39madd(cpp_mapped_f)\n\u001b[1;32m   1606\u001b[0m pmap_f \u001b[38;5;241m=\u001b[39m wraps(fun)(cpp_mapped_f)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae_loader = MNISTVAEDataLoader(\n",
    "    batch_size=config.training.batch_size,\n",
    "    num_mc_samples=config.training.num_mc_samples,\n",
    "    latent_dim=config.eps_dim,\n",
    "    seed=config.seed\n",
    ")\n",
    "\n",
    "# Get info about the dataset\n",
    "_, ds_info = vae_loader._load_dataset()\n",
    "steps_per_epoch = ds_info.splits['train'].num_examples // config.training.batch_size\n",
    "\n",
    "# Get data iterator\n",
    "rng_key = random.PRNGKey(config.seed)\n",
    "train_ds = vae_loader.get_iterator(rng_key)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "total_steps = steps_per_epoch * config.training.num_epochs\n",
    "\n",
    "with tqdm(total=total_steps, desc=\"Training\") as pbar:\n",
    "    global_step = 0  # Add this global step counter\n",
    "    \n",
    "    for epoch in range(config.training.num_epochs):        \n",
    "        for step in range(steps_per_epoch):\n",
    "            # Get next batch: (images, labels, eps)\n",
    "            images, labels, eps = next(train_ds)\n",
    "            batch = (images, eps)\n",
    "            model.state = model.step(model.state, batch)\n",
    "            \n",
    "            # Use global_step for wandb logging\n",
    "            if step % config.logging.log_every_steps == 0:\n",
    "                log_dict = eval_step(config, model, batch)\n",
    "                \n",
    "                # Log with global_step instead of step\n",
    "                wandb.log(log_dict, global_step)\n",
    "                \n",
    "                # Update the progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'kl_loss': f\"{log_dict['kl_loss']:.4f}\", \n",
    "                    'recon_loss': f\"{log_dict['recon_loss']:.4f}\",\n",
    "                    'epoch': epoch + 1\n",
    "                })\n",
    "                \n",
    "                # You can also add epoch information to wandb logs\n",
    "                log_dict['epoch'] = epoch + 1\n",
    "            \n",
    "            # Update progress bar and increment global step\n",
    "            pbar.update(1)\n",
    "            global_step += 1\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ae350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
